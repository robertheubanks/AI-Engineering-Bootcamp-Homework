{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robertheubanks/AI-Engineering-Bootcamp-Homework/blob/main/Eubanks_Week2_Assignment_4_OpenAI_Assistants_Building_Agentic_RAG_with_Function_Calling_API_and_Retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI Assistants - Building Agentic RAG with the Function Calling, Retrieval, and Code Interpreter Tools\n",
        "\n",
        "Today we'll explore using OpenAI's Python SDK to create, manage, and use the OpenAI Assistant API!"
      ],
      "metadata": {
        "id": "RgDepNVhvzIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies\n",
        "\n",
        "We'll start, as we usually do, with some dependiencies and our API key!"
      ],
      "metadata": {
        "id": "RNU6b3ymwOWq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ePayyL6at6LS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac5f278-0bfe-4b99-b381-a3e7e51646d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unKr3HZdu-1V",
        "outputId": "28f3dc1f-2643-4de7-ad07-01135e4b8c7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Assistant\n",
        "\n",
        "Let's create a simple Assistant to understand more about how the API works to start!"
      ],
      "metadata": {
        "id": "nwNE7N4HwhXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI Client\n",
        "\n",
        "At the core of the OpenAI Python SDK is the Client!\n",
        "\n",
        "> NOTE: For ease of use, we'll start with the synchronous `OpenAI()`. OpenAI does provide an `AsyncOpenAI()` that you could leverage as well!"
      ],
      "metadata": {
        "id": "KKEwbLMFxNKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "wF-mBZwtuavl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating An Assistant\n",
        "\n",
        "Leveraging what we know about the OpenAI API from previous sessions - we're going to start by simply initializing an Assistant.\n",
        "\n",
        "Before we begin, we need to think about a few customization options we have:\n",
        "\n",
        "- `name` - Straight forward enough, this is what our Assistant's name will be\n",
        "- `instructions` - similar to a system message, but applied at an Assistant level, this is how we can guide the Assistant's tone, behaviour, functionality, and more!\n",
        "- `model` - this will allow us to choose which model we would prefer to use for our Assistant\n",
        "\n",
        "Let's start by setting some instructions for our Assistant.\n",
        "\n"
      ],
      "metadata": {
        "id": "0aIx4GZ2w_1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown #### üèóÔ∏è Build Activity üèóÔ∏è\n",
        "# @markdown Fill out the fields below to add your Assistant's name, instructions, and desired model!\n",
        "\n",
        "name = \"pharmaceutical medical affairs\" # @param {type: \"string\"}\n",
        "instructions = \"Integrate the intended audience in the prompt, e.g., the audience is an expert in the field.\" # @param {type: \"string\"}\n",
        "model = \"gpt-3.5-turbo\" # @param [\"gpt-3.5-turbo\", \"gpt-4-turbo-preview\", \"gpt-4\"]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Paqd6zWMyMAJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Assistant\n",
        "\n",
        "Now that we have our desired name, instruction, and model - we can initialize our Assistant!"
      ],
      "metadata": {
        "id": "WUeaDsLMzcv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=name,\n",
        "    instructions=instructions,\n",
        "    model=model,\n",
        ")"
      ],
      "metadata": {
        "id": "6-4MgVLbu8rO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's examine our `assistant` object and see what we find!"
      ],
      "metadata": {
        "id": "QskO5n5W2X6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkkIC_JP2bG0",
        "outputId": "6a6b9060-fec9-4837-e29b-853c19a1fbfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Assistant(id='asst_RqFcNcV7q5Tgpe1g1KntLqKy', created_at=1708808796, description=None, file_ids=[], instructions='Integrate the intended audience in the prompt, e.g., the audience is an expert in the field.', metadata={}, model='gpt-3.5-turbo', name='pharmaceutical medical affairs', object='assistant', tools=[])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are a number of useful parameters here, but we'll call out a few:\n",
        "\n",
        "- `id` - since we may have multiple Assistant's, knowing which Assistant we're interacting with will help us ensure the desired user experience!\n",
        "- `description` - A natrual language description of our Assistant could help others understand what it's supposed to do!\n",
        "- `file_ids` - if we wanted to use the Retrieval tool, this would let us know what files we had given our Assistant"
      ],
      "metadata": {
        "id": "615NK1Qj2e_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Thread\n",
        "\n",
        "Behind the scenes our Assistant is powered by the idea of \"threads\".\n",
        "\n",
        "You can think of threads as individual conversations that interact with the Assistant.\n",
        "\n",
        "Let's create a thread now!"
      ],
      "metadata": {
        "id": "-3HhlqtM0AhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create()"
      ],
      "metadata": {
        "id": "iFVM39vevT5f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at our `thread` object."
      ],
      "metadata": {
        "id": "_Y7jelq01PoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V8WAKDZ1Uf2",
        "outputId": "0b66d5de-8887-461a-ab5d-3546f9d4e140"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Thread(id='thread_rU95OKwF9hkd4AatHg8nCzPR', created_at=1708808819, metadata={}, object='thread')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice some key attributes:\n",
        "\n",
        "- `id` - since each Thread is like a conversation, we need some way to specify which thread we're dealing with when interacting with them\n",
        "- `tool_resources` - this will become more relevant as we add tools since we'll need a way to verify which tools we have access to when interacting with our Assistant"
      ],
      "metadata": {
        "id": "4k6S_e501V4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Messages to Our Thread\n",
        "\n",
        "Now that we have our Thread (or conversation) we can start adding messages to it!\n",
        "\n",
        "Let's add a simple message that asks about how our Assistant is feeling.\n",
        "\n",
        "Notice the parameters we're leveraging:\n",
        "\n",
        "- `thread_id` - since each Thread is like a conversation, we need some way to address a specific conversation. We can use `thread.id` to do this.\n",
        "- `role` - similar to when we used our chat completions endpoint, this parameter specifies who the message is coming from. You can leverage this in the same ways you would through the chat completions endpoint.\n",
        "- `content` - this is where we can place the actual text our Assistant will interact with\n",
        "\n",
        "> NOTE: Feel free to substitute a relevant message based on the Assistant you created"
      ],
      "metadata": {
        "id": "P5BvGv1N0c2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=f\"How old are you?\"\n",
        ")"
      ],
      "metadata": {
        "id": "R7ZNCfGivagg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, let's examine our `message` object!"
      ],
      "metadata": {
        "id": "Uc7R3Sr32P0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMLvyZDA2S_D",
        "outputId": "3eacbd80-117d-492e-9e85-46d08124fe1a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreadMessage(id='msg_n9uLZk5FvAVGzsx1HzBFo9v9', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='How old are you?'), type='text')], created_at=1708808855, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_rU95OKwF9hkd4AatHg8nCzPR')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running Our Thread\n",
        "\n",
        "Now that we have an Assistant, and we've given that Assistant a Thread, and we've added a Message to that Thread - we're ready to run our Assistant!\n",
        "\n",
        "Notice that this process lets us add (potentially) multiple messages to our Assistant. We can leverage that behaviour for few/many-shot examples, and more!"
      ],
      "metadata": {
        "id": "uI3Pctpk29og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown #### üèóÔ∏è Build Activity üèóÔ∏è\n",
        "# @markdown We can also override the Assistant's instructions when we run a thread.\n",
        "\n",
        "# @markdown Use one of the [Prompt Principles for Instruction](https://arxiv.org/pdf/2312.16171v1.pdf) to improve the likeliehood of a correct or valuable response from your Assistant.\n",
        "\n",
        "additional_instructions = \"Break down complex tasks into a sequence of simpler prompts in an interactive conversation.\" # @param {type: \"string\"}"
      ],
      "metadata": {
        "id": "VkvsXv5_3cyQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run our Thread!"
      ],
      "metadata": {
        "id": "7CuGbTrL5QEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        "  instructions=instructions + \" \" + additional_instructions\n",
        ")"
      ],
      "metadata": {
        "id": "fpWNl3UVvdW4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've run our thread, let's look at the object!"
      ],
      "metadata": {
        "id": "erMGdU7y6la2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz_rfwi869YI",
        "outputId": "d032f620-fe10-41ed-e57c-d3db319e04ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Run(id='run_4lzU51Q647ocgIb8cNeNPsmz', assistant_id='asst_RqFcNcV7q5Tgpe1g1KntLqKy', cancelled_at=None, completed_at=None, created_at=1708809835, expires_at=1708810435, failed_at=None, file_ids=[], instructions='Integrate the intended audience in the prompt, e.g., the audience is an expert in the field. Break down complex tasks into a sequence of simpler prompts in an interactive conversation.', last_error=None, metadata={}, model='gpt-3.5-turbo', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_rU95OKwF9hkd4AatHg8nCzPR', tools=[], usage=None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice we have access to a few very powerful parameters in this `run` object.\n",
        "\n",
        "- `completed_at` - this will help us determine when we can expect to retrieve a response\n",
        "- `failed_at` - this can highlight any issues our run ran into\n",
        "- `status` - is another way we can understand how the flow is going"
      ],
      "metadata": {
        "id": "-h2SH_347JJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieving Our Run\n",
        "\n",
        "Now that we've created our run, let's retrieve it.\n",
        "\n",
        "We're going to wrap this in a simple loop to make sure we're not retrieving it too early."
      ],
      "metadata": {
        "id": "HVBNagBU7kpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "while run.status == \"in_progress\" or run.status == \"queued\":\n",
        "  time.sleep(1)\n",
        "  run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )"
      ],
      "metadata": {
        "id": "itz5_otPvfkV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run.status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgGE1uUJ7z3h",
        "outputId": "d7a164e3-3067-4978-c28a-36de227a5e98"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our run is completed - we can retieve the messages from our thread!\n",
        "\n",
        "Notice that our run helps us understand how things are going - but it isn't where we're going to find our responses or messages. Those are added on the backend into our thread.\n",
        "\n",
        "This leads to a simple, but important, flow:\n",
        "\n",
        "1. We add messages to a thread.\n",
        "2. We create a run on that thread.\n",
        "3. We wait until the run is finished.\n",
        "4. We check our thread for the new messages."
      ],
      "metadata": {
        "id": "zHVTS4hD7-fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking Our Thread\n",
        "\n",
        "Now we can get a list of messages from our thread!"
      ],
      "metadata": {
        "id": "DGBNpGmh-ZpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ],
      "metadata": {
        "id": "Av-OQDUPvhAd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM6cZk-GviqX",
        "outputId": "13781d9d-fcbf-4bf6-8b95-45b26f8de0b6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreadMessage(id='msg_o6ZBWXXEauADWI0Hox26M1Ji', assistant_id='asst_RqFcNcV7q5Tgpe1g1KntLqKy', content=[MessageContentText(text=Text(annotations=[], value='What specific information or assistance do you need help with? Feel free to ask any questions or provide details about the task you would like assistance with.'), type='text')], created_at=1708809836, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_4lzU51Q647ocgIb8cNeNPsmz', thread_id='thread_rU95OKwF9hkd4AatHg8nCzPR')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Tools\n",
        "\n",
        "Now that we have an understanding of how Assistant works, we can start thinking about adding tools.\n",
        "\n",
        "We'll go through 3 separate tools and explore how we can leverage them!\n",
        "\n",
        "Let's start with the most familiar tool - the Retriever!\n"
      ],
      "metadata": {
        "id": "XgnY16tjCmc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an Assistant with the Retriever Tool\n",
        "\n",
        "The first thing we'll want to do is create an assistant with the Retriever tool.\n",
        "\n",
        "This is also going to require some data. We'll provided data - but you're very much encouraged to use your own files to explore how the Assistant works for your use case."
      ],
      "metadata": {
        "id": "Z0NagnlZC8g9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Collect and Add Data\n",
        "\n",
        "First, we need some data. Second, we need to add the data to our Assistant!\n",
        "\n",
        "Let's start with grabbing some data!"
      ],
      "metadata": {
        "id": "HInYwNiQEjQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.gutenberg.org/files/84/84-h/84-h.htm -o frankenstein.html"
      ],
      "metadata": {
        "id": "wvAHBszIEa1Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can upload our file!\n",
        "\n",
        "Pay attention to [this](https://platform.openai.com/docs/assistants/tools/supported-files) documentation to see what kinds of files can be uploaded.\n",
        "\n",
        "> NOTE: Per the OpenAI [docs](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval) The maximum file size is 512 MB and no more than 2,000,000 tokens (computed automatically when you attach a file)"
      ],
      "metadata": {
        "id": "x2EpY1w_FQ3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_reference = client.files.create(\n",
        "  file=open(\"frankenstein.html\", \"rb\"),\n",
        "  purpose='assistants'\n",
        ")"
      ],
      "metadata": {
        "id": "dpVoe2SMFI6s"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at what our `file_reference` contains!"
      ],
      "metadata": {
        "id": "rBQOSGyyF2u5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_reference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJrVLkMpFgwf",
        "outputId": "fe8b290a-2513-4ef3-be58-caf19ad48cd4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-beVB3N0ACDPUuWWbRQoOg7cn', bytes=1199, created_at=1708810429, filename='frankenstein.html', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create and Use Assistant\n",
        "\n",
        "Now that we have our file - we can attach it to an Assistant, and we can give that Assistant the ability to use it for retrieval through the Retrieval tool!\n",
        "\n",
        "> NOTE: Please pay attention to [pricing](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval) and don't forget to delete your files when you're done!"
      ],
      "metadata": {
        "id": "Jd4O4dpZF-eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=name + \"+ Retrieval\",\n",
        "  instructions=instructions,\n",
        "  model=model,\n",
        "  tools=[{\"type\": \"retrieval\"}],\n",
        "  file_ids=[file_reference.id]\n",
        ")"
      ],
      "metadata": {
        "id": "jfn_MlJqFiEe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try submitting a message to our Assistant and seeing what kind of answer we get!\n",
        "\n",
        "We'll outline the steps needed to do this in full:\n",
        "\n",
        "1. Create an Assistant\n",
        "2. Create a Thread\n",
        "3. Add Messages to that Thread\n",
        "4. Create a Run on that Thread\n",
        "5. Wait for Run to Complete\n",
        "6. Collect Messages from the Thread\n",
        "\n",
        "Let's do that below!"
      ],
      "metadata": {
        "id": "f0-mmRjQGeUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Thread\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "# Add Messages to that Thread\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=f\"What is the first words Victor Frankenstein speaks?\"\n",
        ")\n",
        "\n",
        "# Create a Run on that Thread\n",
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        ")\n",
        "\n",
        "# Wait for Run to Complete\n",
        "while run.status == \"in_progress\" or run.status == \"queued\":\n",
        "  time.sleep(1)\n",
        "  print(run.status)\n",
        "  run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )\n",
        "\n",
        "# Collect Messages from the Thread\n",
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOKtb9PsGiB1",
        "outputId": "96013784-143f-41e3-dc7f-54985d3b1503"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queued\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the final result!"
      ],
      "metadata": {
        "id": "zxJfa-saHbNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19nDqjRgHaNA",
        "outputId": "6516b7c0-e4da-4635-af0a-bf5bf3279a57"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_FOd9fd9LfNP9jxg61B7CZpq8', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is the first words Victor Frankenstein speaks?'), type='text')], created_at=1708810459, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_2C7lu8j84vou5AuzN4gHCgly')], object='list', first_id='msg_FOd9fd9LfNP9jxg61B7CZpq8', last_id='msg_FOd9fd9LfNP9jxg61B7CZpq8', has_more=False)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do some clean up to make sure we're not being charged anything extra by deleting our resources."
      ],
      "metadata": {
        "id": "5JdzJDvmHyNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_deletion_status = client.beta.assistants.files.delete(\n",
        "  assistant_id=assistant.id,\n",
        "  file_id=file_reference.id\n",
        ")"
      ],
      "metadata": {
        "id": "01EYWyWBHaoC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an Assistant with the Code Interpreter Tool\n",
        "\n",
        "Now that we've explored the Retrieval Tool - let's try the Code Interpreter tool!\n",
        "\n",
        "The process will be almost exactly the same - but we can explore a different query, and we'll add our file at the Message level!"
      ],
      "metadata": {
        "id": "Pln9uYoJICno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=name + \"+ Code Interpreter\",\n",
        "  instructions=instructions,\n",
        "  model=model,\n",
        "  tools=[{\"type\": \"code_interpreter\"}],\n",
        ")"
      ],
      "metadata": {
        "id": "IC81y_VtH9lw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following example, we'll also see how we can package the Thread creation with the Message adding step!\n",
        "\n",
        "> NOTE: Files added at the message/thread level will not be available to the Assistant outside of that Thread."
      ],
      "metadata": {
        "id": "UJPHAJCQJbgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"What kind of file is this?\",\n",
        "      \"file_ids\": [file_reference.id]\n",
        "    }\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "5xVdjH6EJQrr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> NOTE: Remember that we create runs at the *thread* level - and so don't need the message object to continue."
      ],
      "metadata": {
        "id": "yiIYut_dJ0Cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Run on that Thread\n",
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        ")\n",
        "\n",
        "# Wait for Run to Complete\n",
        "while run.status == \"in_progress\" or run.status == \"queued\":\n",
        "  time.sleep(1)\n",
        "  print(run.status)\n",
        "  run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )\n",
        "\n",
        "# Collect Messages from the Thread\n",
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES8laUe_Jwp_",
        "outputId": "87323c43-d457-45cb-f18b-6f816db62d5a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queued\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the specific steps that the Code Interpreter ran to figure out what steps the Assistant took!"
      ],
      "metadata": {
        "id": "iYPpGJz5KoDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_steps = client.beta.threads.runs.steps.list(\n",
        "  thread_id=thread.id,\n",
        "  run_id=run.id\n",
        ")"
      ],
      "metadata": {
        "id": "or7iJ492KI2P"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in run_steps.data:\n",
        "  print(step.step_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwbzExbmKJ4N",
        "outputId": "e7ec11e7-3125-480f-b440-d1afaaf49dd8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_iE8dKyR7JoDWtIDHQK3JNDMp'), type='message_creation')\n",
            "ToolCallsStepDetails(tool_calls=[CodeToolCall(id='call_gPJfsOpVcFjgv9Xl5uLI0cZm', code_interpreter=CodeInterpreter(input=\"# Read the first few lines of the file to identify its content\\r\\nwith open(file_path, 'r') as file:\\r\\n    first_few_lines = [next(file) for _ in range(5)]\\r\\n\\r\\nfirst_few_lines\", outputs=[CodeInterpreterOutputLogs(logs=\"['--2024-02-24 21:33:36--  https://www.gutenberg.org/files/84/84-h/84-h.htm\\\\n',\\n 'Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\\\\n',\\n 'Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\\\\n',\\n 'HTTP request sent, awaiting response... 200 OK\\\\n',\\n 'Length: 466919 (456K) [text/html]\\\\n']\", type='logs')]), type='code_interpreter')], type='tool_calls')\n",
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_kmYQ5hbN7vFyzhdAsmQediA3'), type='message_creation')\n",
            "ToolCallsStepDetails(tool_calls=[CodeToolCall(id='call_pXxGNiEmfRIOcP79k3rS31lM', code_interpreter=CodeInterpreter(input=\"import mimetypes\\n\\n# Define the file path\\nfile_path = '/mnt/data/file-beVB3N0ACDPUuWWbRQoOg7cn'\\n\\n# Determine the file type based on the file extension\\nfile_extension = file_path.split('.')[-1]\\nfile_type = mimetypes.types_map.get('.' + file_extension.lower(), 'Unknown File Type')\\n\\nfile_type\", outputs=[CodeInterpreterOutputLogs(logs=\"'Unknown File Type'\", type='logs')]), type='code_interpreter')], type='tool_calls')\n",
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_EbtHNCGcgmpoQZ7RpIQlhNl0'), type='message_creation')\n",
            "ToolCallsStepDetails(tool_calls=[CodeToolCall(id='call_DL460FniAPj3YnDbFaPCQEQL', code_interpreter=CodeInterpreter(input=\"import mimetypes\\n\\n# Determine the file type based on the file extension\\nfile_extension = file_path.split('.')[-1]\\nfile_type = mimetypes.types_map.get('.' + file_extension.lower(), 'Unknown File Type')\\n\\nfile_type\", outputs=[CodeInterpreterOutputLogs(logs=\"---------------------------------------------------------------------------\\nNameError                                 Traceback (most recent call last)\\nCell In[2], line 4\\n      1 import mimetypes\\n      3 # Determine the file type based on the file extension\\n----> 4 file_extension = file_path.split('.')[-1]\\n      5 file_type = mimetypes.types_map.get('.' + file_extension.lower(), 'Unknown File Type')\\n      7 file_type\\n\\nNameError: name 'file_path' is not defined\\n\", type='logs')]), type='code_interpreter')], type='tool_calls')\n",
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_cRhkk1FPyXPiyO8QPMTCtldb'), type='message_creation')\n",
            "ToolCallsStepDetails(tool_calls=[CodeToolCall(id='call_P6J00LOU8HeUGeC5fRSVhcLT', code_interpreter=CodeInterpreter(input=\"import magic\\r\\n\\r\\n# Get the MIME type of the uploaded file\\r\\nfile_path = '/mnt/data/file-beVB3N0ACDPUuWWbRQoOg7cn'\\r\\nfile_type = magic.Magic(mime=True)\\r\\nmime_type = file_type.from_file(file_path)\\r\\n\\r\\nmime_type\", outputs=[CodeInterpreterOutputLogs(logs=\"---------------------------------------------------------------------------\\nModuleNotFoundError                       Traceback (most recent call last)\\nCell In[1], line 1\\n----> 1 import magic\\n      3 # Get the MIME type of the uploaded file\\n      4 file_path = '/mnt/data/file-beVB3N0ACDPUuWWbRQoOg7cn'\\n\\nModuleNotFoundError: No module named 'magic'\\n\", type='logs')]), type='code_interpreter')], type='tool_calls')\n",
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_ion6frOhSQek0Fwuf9C28ukJ'), type='message_creation')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNJeFF6JJ62H",
        "outputId": "966c0c50-035c-4df7-cd7f-1aef83e5ed3d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_iE8dKyR7JoDWtIDHQK3JNDMp', assistant_id='asst_UPFWO69Kk8CNDGlZh7zJ2vc1', content=[MessageContentText(text=Text(annotations=[], value='The first few lines of the file contain information about a web request to \"https://www.gutenberg.org/files/84/84-h/84-h.htm\". It appears to be an HTML file from Project Gutenberg (a digital library of free eBooks). \\n\\nTherefore, based on the content, it is identified as an HTML file. Is there anything else you would like to know or do with this file?'), type='text')], created_at=1708810542, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_oQvKAvCjMmXMAiGnsheuJePR', thread_id='thread_rmfp7YdgGPYRYo6YcJ7gWyLa'), ThreadMessage(id='msg_kmYQ5hbN7vFyzhdAsmQediA3', assistant_id='asst_UPFWO69Kk8CNDGlZh7zJ2vc1', content=[MessageContentText(text=Text(annotations=[], value='The file type could not be determined based on the file extension. Let me try to read the file to see if there are any visible clues within the content that might help identify the file type.'), type='text')], created_at=1708810539, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_oQvKAvCjMmXMAiGnsheuJePR', thread_id='thread_rmfp7YdgGPYRYo6YcJ7gWyLa'), ThreadMessage(id='msg_EbtHNCGcgmpoQZ7RpIQlhNl0', assistant_id='asst_UPFWO69Kk8CNDGlZh7zJ2vc1', content=[MessageContentText(text=Text(annotations=[], value='It seems I forgot to define the `file_path` variable while attempting to check the file type. Let me correct that and try again.'), type='text')], created_at=1708810536, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_oQvKAvCjMmXMAiGnsheuJePR', thread_id='thread_rmfp7YdgGPYRYo6YcJ7gWyLa'), ThreadMessage(id='msg_cRhkk1FPyXPiyO8QPMTCtldb', assistant_id='asst_UPFWO69Kk8CNDGlZh7zJ2vc1', content=[MessageContentText(text=Text(annotations=[], value='It seems that the library `python-magic` is not available in this environment to determine the file type. Let me try an alternative method to identify the file type.'), type='text')], created_at=1708810533, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_oQvKAvCjMmXMAiGnsheuJePR', thread_id='thread_rmfp7YdgGPYRYo6YcJ7gWyLa'), ThreadMessage(id='msg_ion6frOhSQek0Fwuf9C28ukJ', assistant_id='asst_UPFWO69Kk8CNDGlZh7zJ2vc1', content=[MessageContentText(text=Text(annotations=[], value=\"I will check the file type for you. Let's read the content of the file to identify its type.\"), type='text')], created_at=1708810528, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_oQvKAvCjMmXMAiGnsheuJePR', thread_id='thread_rmfp7YdgGPYRYo6YcJ7gWyLa'), ThreadMessage(id='msg_FPrDa1citgnnUb4kep8uxn5Q', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What kind of file is this?'), type='text')], created_at=1708810521, file_ids=['file-beVB3N0ACDPUuWWbRQoOg7cn'], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_rmfp7YdgGPYRYo6YcJ7gWyLa')], object='list', first_id='msg_iE8dKyR7JoDWtIDHQK3JNDMp', last_id='msg_FPrDa1citgnnUb4kep8uxn5Q', has_more=False)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_deletion_status = client.beta.assistants.files.delete(\n",
        "  assistant_id=assistant.id,\n",
        "  file_id=file_reference.id\n",
        ")"
      ],
      "metadata": {
        "id": "JdLC0rsvR5m5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "7192e4c8-ae71-4db6-fc5f-93b6d26f1c2b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Error code: 404 - {'error': {'message': \"No file found with id 'file-beVB3N0ACDPUuWWbRQoOg7cn'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-f147d1f60477>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m file_deletion_status = client.beta.assistants.files.delete(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0massistant_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massistant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mfile_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_reference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/beta/assistants/files.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, file_id, assistant_id, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected a non-empty value for `file_id` but received {file_id!r}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mextra_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"OpenAI-Beta\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"assistants=v1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_headers\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         return self._delete(\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;34mf\"/assistants/{assistant_id}/files/{file_id}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             options=make_request_options(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, path, cast_to, body, options)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     ) -> ResponseT:\n\u001b[1;32m   1235\u001b[0m         \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFinalRequestOptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"delete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m     def get_api_list(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 889\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': \"No file found with id 'file-beVB3N0ACDPUuWWbRQoOg7cn'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And there you go!\n",
        "\n",
        "We've fit our Assistant with an awesome Code Interpreter that lets our Assistant run code on our provided files!"
      ],
      "metadata": {
        "id": "hi10hON2LQmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an Assistant with a Function Calling Tool\n",
        "\n",
        "Let's finally create an Assistant that utilizes the Function Calling API.\n",
        "\n",
        "We'll start by creating a function that we wish to be called.\n",
        "\n",
        "We'll utilize DuckDuckGo search to allow our Assistant to have the most up to date information!"
      ],
      "metadata": {
        "id": "EdJxt77oLzu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU duckduckgo_search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5eKEC2wMMVI",
        "outputId": "d7acbc28-9c35-4b7d-feeb-a3ec9c9e7087"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from duckduckgo_search import DDGS\n",
        "\n",
        "def duckduckgo_search(query):\n",
        "  with DDGS() as ddgs:\n",
        "    results = [r for r in ddgs.text(query, max_results=5)]\n",
        "    return \"\\n\".join(result[\"body\"] for result in results)"
      ],
      "metadata": {
        "id": "YPFZ_Uq_LawH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our function to make sure it behaves as we expect it to."
      ],
      "metadata": {
        "id": "D-o1TBFpMSvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duckduckgo_search(\"Who is the current captain of the Winnipeg Jets?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "mCUr9jFCMWBw",
        "outputId": "b7e0692f-8f22-4aeb-eaa7-fcee1d252945"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NHL.com The official 2023 - 2024 roster of the Winnipeg Jets, including position, height, weight, date of birth, age, and birth place.\\nManitoba Adam Lowry named new captain of Winnipeg Jets 30-year-old centre is 3rd captain since team relocated to Winnipeg from Atlanta Darren Bernhardt ¬∑ CBC News ¬∑ Posted: Sep 12, 2023...\\nWinnipeg Jets general manager Kevin Cheveldayoff announced Adam Lowry as the new team captain of the Winnipeg Jets on tuesday. Lowry will follow Andrew Ladd and Blake Wheeler to serve as...\\nMost Goals, Season: Ilya Kovalchuk (2005-06), Ilya Kovalchuk (2007-08), 52 Most Points, Season: Mari√°n Hossa (2006-07), 100 Become a Stathead & surf this site ad-free. Jets History Leaders Skaters Goalies Coaches Draft Captains Sweater #s All-Time W-L Records More Captains More Jets Pages Jets History More Jets Pages Leaders Season Leaders\\nTrade deadline Jets name Adam Lowry as captain ahead of 2023-24 season: Why Winnipeg chose him By Murat Ates and The Athletic Staff Sep 12, 2023 60 The Winnipeg Jets finally have a...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to express how our function works in a way that is compatible with the OpenAI Function Calling API.\n",
        "\n",
        "We'll want to provide a `JSON` object that includes what parameters we have, how to call them, and a short natural language description."
      ],
      "metadata": {
        "id": "FzE1nxt5Mi80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddg_function = {\n",
        "    \"name\" : \"duckduckgo_search\",\n",
        "    \"description\" : \"Answer non-technical questions. \",\n",
        "    \"parameters\" : {\n",
        "        \"type\" : \"object\",\n",
        "        \"properties\" : {\n",
        "            \"query\" : {\n",
        "                \"type:\" : \"string\",\n",
        "                \"description\" : \"The search query to use. For example: 'Who is the current Goalie of the Colorado Avalance?'\"\n",
        "            }\n",
        "        },\n",
        "        \"required\" : [\"query\"]\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "8ElrWvBnMY_s"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####‚ùì Question\n",
        "\n",
        "Why does the description key-value pair matter?"
      ],
      "metadata": {
        "id": "NyRmJgEQVuGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER:\n",
        "The description key-value pair in the context of defining a function for use with an API, especially one designed to be part of an assistant or AI-driven service, plays several crucial roles that are important both technically and from a user-experience perspective.\n",
        "\n",
        "\n",
        "*   User Understanding: It provides a clear, concise description of what the function does, which is essential for users who may be integrating or calling this function within their own systems or workflows. This is particularly valuable in environments where developers may be dealing with a large number of available functions and need to quickly understand the purpose and utility of each one.\n",
        "*   Documentation: Automatically generated documentation can leverage these descriptions to provide more insightful and useful information. This improves the overall documentation quality and usability for developers who are exploring or learning about the API.\n",
        "*   Searchability: In a large API with many endpoints or functions, the description helps in indexing the functions for search operations. Developers can find the functions they need by searching for keywords or phrases, making the API more accessible and easier to use.\n",
        "*   Integrations and Compatibility: For systems that may dynamically call APIs based on certain criteria or inputs, the description provides a human-readable explanation of the function's capabilities, aiding in the selection process for automated workflows or AI-driven decision-making processes.\n",
        "*   Accessibility: In the context of making technology accessible to a broader audience, including those who may not be deeply technical, descriptions can demystify what a function does and how it can be used, thereby lowering the barrier to entry.\n",
        "*   Quality Assurance and Maintenance: Descriptions also serve an internal purpose, helping developers and maintainers of the API understand the intended use and scope of each function. This can be invaluable during maintenance, debugging, and when extending the functionality of the API."
      ],
      "metadata": {
        "id": "oEO24kt8ELCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now when we create our Assistant - we'll want to include the function description as a tool using the following format."
      ],
      "metadata": {
        "id": "tir4WySGM0x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=name + \" + Function Calling API\",\n",
        "    instructions=instructions,\n",
        "    tools=[\n",
        "        {\"type\": \"function\",\n",
        "         \"function\" : ddg_function\n",
        "        }\n",
        "    ],\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "4eFpwi12Mzlg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to make a few modifications to our Assistant to include the ability to make calls to our local function and pass the results back to our Assistant for further generation."
      ],
      "metadata": {
        "id": "nJCLvWZzNIXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def wait_for_run_completion(thread_id, run_id):\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
        "        print(f\"Current run status: {run.status}\")\n",
        "        if run.status in ['completed', 'failed', 'requires_action']:\n",
        "            return run\n",
        "\n",
        "def submit_tool_outputs(thread_id, run_id, tools_to_call):\n",
        "    tool_output_array = []\n",
        "    for tool in tools_to_call:\n",
        "        output = None\n",
        "        tool_call_id = tool.id\n",
        "        function_name = tool.function.name\n",
        "        function_args = tool.function.arguments\n",
        "\n",
        "        if function_name == \"duckduckgo_search\":\n",
        "            print(\"Consulting Duck Duck Go...\")\n",
        "            output = duckduckgo_search(query=json.loads(function_args)[\"query\"])\n",
        "\n",
        "        if output:\n",
        "            tool_output_array.append({\"tool_call_id\": tool_call_id, \"output\": output})\n",
        "\n",
        "    print(tool_output_array)\n",
        "\n",
        "    return client.beta.threads.runs.submit_tool_outputs(\n",
        "        thread_id=thread_id,\n",
        "        run_id=run_id,\n",
        "        tool_outputs=tool_output_array\n",
        "    )\n",
        "\n",
        "def print_messages_from_thread(thread_id):\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
        "    for msg in messages:\n",
        "        print(f\"{msg.role}: {msg.content[0].text.value}\")\n",
        "\n",
        "def use_assistant(query, assistant_id, thread_id=None):\n",
        "  thread = client.beta.threads.create()\n",
        "\n",
        "  message = client.beta.threads.messages.create(\n",
        "      thread_id=thread.id,\n",
        "      role=\"user\",\n",
        "      content=query,\n",
        "  )\n",
        "\n",
        "  print(\"Creating Assistant \")\n",
        "\n",
        "  run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant_id,\n",
        "  )\n",
        "\n",
        "  print(\"Querying OpenAI Assistant Thread.\")\n",
        "\n",
        "  run = wait_for_run_completion(thread.id, run.id)\n",
        "\n",
        "  if run.status == 'requires_action':\n",
        "    run = submit_tool_outputs(thread.id, run.id, run.required_action.submit_tool_outputs.tool_calls)\n",
        "    run = wait_for_run_completion(thread.id, run.id)\n",
        "\n",
        "  print_messages_from_thread(thread.id)\n",
        "\n",
        "  return thread.id"
      ],
      "metadata": {
        "id": "XHRfvGJ_NQnF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####‚ùì Question\n",
        "\n",
        "Outline, in simple terms, what the `use_assistant` helper function is doing."
      ],
      "metadata": {
        "id": "NoChJ771Uo0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER:\n",
        "The use_assistant helper function orchestrates the interaction between a user and an AI Assistant that has the capability to call external functions as part of its processing. The function achieves this through a series of steps, structured to ensure that the assistant can not only generate responses but also execute defined functions (like duckduckgo_search) to enrich those responses with external data or computations. Here's a breakdown of its operation:\n",
        "\n",
        "*   Thread Creation: It starts by creating a new conversation thread with the assistant. This thread acts as a container for the interaction, allowing for an organized exchange of messages between the user and the assistant.\n",
        "Sending a Query: The user's query is sent to the assistant as a message within the created thread. This is the question or request the user wants the assistant to process.\n",
        "*   Initiating Assistant Processing: The function then requests the assistant to start processing the user's query within the thread. This is akin to \"asking\" the assistant to think about the question and come up with a response.\n",
        "*   Monitoring for Completion: The function enters a wait state, periodically checking if the assistant has completed processing the query. This step is crucial because the assistant might need time to consider the query, especially if external functions need to be called.\n",
        "*   Handling Required Actions: If the assistant's processing requires calling an external function (like the DuckDuckGo search), the function identifies this need and executes the appropriate external function to obtain the necessary data or results.\n",
        "*   Submitting External Function Outputs: Once the external function's output is obtained, it is submitted back to the assistant. This allows the assistant to incorporate the external data into its final response.\n",
        "*   Finalizing the Response: The function waits again, if necessary, for the assistant to finalize its response, now with the added context or data from the external function.\n",
        "*   Displaying the Assistant's Messages: Finally, the function retrieves and displays the messages from the assistant found in the thread. This includes the assistant's response to the initial query, enriched or informed by the data from the external function call."
      ],
      "metadata": {
        "id": "P1ONmHq3FR9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_assistant(\"Who is the current Captain of the Winnipeg Jets?\", assistant.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "d5NR_HYINky8",
        "outputId": "8228adbb-7b7f-442a-defb-0e78dc742dd4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: requires_action\n",
            "Consulting Duck Duck Go...\n",
            "[{'tool_call_id': 'call_lREXZyaoKgkiRa5nMUtMKt3O', 'output': \"NHL.com The official 2023 - 2024 roster of the Winnipeg Jets, including position, height, weight, date of birth, age, and birth place.\\nWinnipeg Jets general manager Kevin Cheveldayoff announced Adam Lowry as the new team captain of the Winnipeg Jets on tuesday. Lowry will follow Andrew Ladd and Blake Wheeler to serve as...\\nSault Ste. Marie Toronto Vancouver Vancouver Island Windsor Winnipeg Advertisement Winnipeg News Adam Lowry named as captain of the Winnipeg Jets Winnipeg Jets' Adam Lowry celebrates...\\nManitoba Adam Lowry named new captain of Winnipeg Jets 30-year-old centre is 3rd captain since team relocated to Winnipeg from Atlanta Darren Bernhardt ¬∑ CBC News ¬∑ Posted: Sep 12, 2023...\\nBy Jamie Thomas @JamieThomasTV WinnipegJets.com September 12, 2023 There are not many honours in team sports bigger than being named captain. That honour was given to Winnipeg Jet forward Adam...\"}]\n",
            "Current run status: completed\n",
            "assistant: The current Captain of the Winnipeg Jets is Adam Lowry. He was announced as the new team captain by Winnipeg Jets general manager Kevin Cheveldayoff.\n",
            "user: Who is the current Captain of the Winnipeg Jets?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thread_4Xdxmp8IovHfd4mjA8eU14GR'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapping it All Together\n",
        "\n",
        "Now we can create an Assistant with all of the available tools and see how it responds to various queries!"
      ],
      "metadata": {
        "id": "vY51QtkGNvQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=name + \" + All Tools\",\n",
        "    instructions=instructions,\n",
        "    tools=[\n",
        "        {\"type\": \"code_interpreter\"},\n",
        "        {\"type\": \"retrieval\"},\n",
        "        {\"type\": \"function\", \"function\" : ddg_function}\n",
        "    ],\n",
        "    model=model,\n",
        "    file_ids=[file_reference.id],\n",
        ")"
      ],
      "metadata": {
        "id": "HaoQSB7CN74T"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_assistant(\"Who is the current Captain of the Winnipeg Jets?\", assistant.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "g2GtwoGDPwp2",
        "outputId": "459ba98a-7b2e-4874-9a32-2f94c1f0a028"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: The uploaded file does not contain information about the current Captain of the Winnipeg Jets. Would you like me to search for this information online?\n",
            "user: Who is the current Captain of the Winnipeg Jets?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thread_Q65M42M8Ywzoarpj9xHjcyIB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_assistant(\"Who is the author of the supplied file?\", assistant.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "7QjcxpQ5P-HX",
        "outputId": "f494ee5e-6671-4d9d-d110-a45904ac8786"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: The author of the supplied file is Mary Shelley.\n",
            "user: Who is the author of the supplied file?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thread_GX2AsMoYjp7efNWTPGYmxee1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_assistant(\"How many bytes is the provided file?\", assistant.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "kSKL96nvQIUq",
        "outputId": "1221814d-07de-4e3e-9bf2-c9217f975d4b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: The provided file is 466,919 bytes in size.\n",
            "user: How many bytes is the provided file?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thread_HNmL9yjmZRL0haVFzGBO2ggr'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####‚ùì Question\n",
        "\n",
        "Notice that our response can go through multiple paths, given that:\n",
        "\n",
        "What is \"deciding\" to use the tool?"
      ],
      "metadata": {
        "id": "gm0oYJu7VAjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER:\n",
        "In the context provided, where an Assistant is equipped with various tools (such as a code interpreter, retrieval tool, and a custom function like duckduckgo_search), the decision-making process regarding which tool to use for a given query is guided by the Assistant's underlying AI model and its instructions. Here‚Äôs how it works:\n",
        "*   Understanding the Query: When a query is received, the Assistant's AI model analyzes the content and context of the query to understand its intent. This involves natural language processing (NLP) capabilities to discern what the user is asking and what kind of response or action is expected.\n",
        "*   Instructions Interpretation: The Assistant relies on the instructions provided during its creation to guide its response behavior. These instructions typically outline how the Assistant should handle various types of queries, potentially indicating when to use specific tools or how to prioritize them.\n",
        "*   Tool Suitability Evaluation: Based on the query‚Äôs understood intent and the instructions, the Assistant evaluates which tool(s) in its arsenal are most suitable for addressing the query. This involves a form of decision-making logic that considers factors like the nature of the query (e.g., factual, computational, data retrieval) and the capabilities of each tool.\n",
        "> For factual questions like \"Who is the current Captain of the Winnipeg Jets?\", the Assistant might decide to use the retrieval tool or the duckduckgo_search function, as these are designed to fetch real-time information from external sources.\n",
        "> For queries asking about content or data within a specific file, like \"Who is the author of the supplied file?\" or \"How many bytes is the provided file?\", the Assistant might leverage the file_ids associated with it and possibly the retrieval tool to extract and compute the requested information.\n",
        "*   Execution and Integration: Once the Assistant decides on the most appropriate tool(s), it executes the necessary tool(s) to gather information or perform computations. The results are then integrated into the Assistant's response generation process, ensuring that the reply is informed by the most relevant and accurate data available.\n",
        "*   Dynamic Response Generation: The Assistant dynamically generates a response to the query, incorporating the outcomes from the used tool(s). This response is crafted to be coherent and directly address the user's query, based on the combination of the AI model's language capabilities and the specific information or computation provided by the tools."
      ],
      "metadata": {
        "id": "TZKttbzHGzyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding JSON Mode for More Agentic Behaviour\n",
        "\n",
        "Finally, we have the ability to select tools - all we need to do now is set up a process to allow us to create some kind of loop and make decisions about whether or not the response is complete or not.\n",
        "\n",
        "We'll leverage the OpenAI completions end-endpoint with JSON mode to let us understand when we've adequately answered our user's question!"
      ],
      "metadata": {
        "id": "FrJWQ4XvZ20K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completed_template = \\\n",
        "\"\"\"\n",
        "Does this response adequately answer the user's query?\n",
        "\n",
        "Please return your response in JSON format - with key: \"completed\" and either True (if completed) or False (if not completed)\n",
        "\n",
        "User Query:\n",
        "{query}\n",
        "\n",
        "Assistant Response:\n",
        "{response}\n",
        "\"\"\"\n",
        "\n",
        "def is_complete(query, response):\n",
        "  completed_response = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": completed_template.format(query=query, response=response),\n",
        "          }\n",
        "      ],\n",
        "      model=model,\n",
        "      response_format={\"type\" : \"json_object\"}\n",
        "  )\n",
        "\n",
        "  return completed_response"
      ],
      "metadata": {
        "id": "Rzrk8gn2anpe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How many bytes is the provided file?\"\n",
        "\n",
        "thread_id_for_response = use_assistant(query, assistant.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kCQrx03brge",
        "outputId": "45a17feb-da8e-4439-d8e4-221661171c3e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: requires_action\n",
            "Consulting Duck Duck Go...\n",
            "[{'tool_call_id': 'call_zHieFhuqsRD67u4g2064WJk6', 'output': 'How do I get the size of a file in Python? python file Share Improve this question Follow edited Apr 17, 2022 at 2:14 Mateen Ulhaq 25.5k 20 105 141 asked Jan 20, 2010 at 18:58 5YrsLaterDBA 33.9k 44 139 211 Add a comment 11 Answers Sorted by: 1484 Use os.path.getsize: >>> import os >>> os.path.getsize(\"/path/to/file.mp3\") 2071611\\nMethod 1: Using getsize function of os.path module This function takes a file path as an argument and it returns the file size (bytes). Example: Python3 # approach 1 import os file_size = os.path.getsize (\\'d:/file.jpg\\') print(\"File Size is :\", file_size, \"bytes\") Output: File Size is : 218 bytes Method 2: Using stat function of the OS module\\nUse the os.path.getsize (\\'file_path\\') function to check the file size. Pass the file name or file path to this function as an argument. This function returns file size in bytes. It raises OSError if the file does not exist or is inaccessible. Example To Get File Size\\nThe Python os library provides two different ways to get the size of a file: the os.path.getsize () function and the os.stat () function. The getsize () function, as the name implies, returns the size of the file. On the other hand, the stat () function returns a number of statistics, or attributes, about the file.\\nExample 1: Using os module import os file_stat = os.stat (\\'my_file.txt\\') print(file_stat.st_size) Run Code Output 34 Using stat () from the os module, you can get the details of a file. Use the st_size attribute of stat () method to get the file size. The unit of the file size is byte. Example 2: Using pathlib module'}]\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: requires_action\n",
            "assistant: I will check the size of the uploaded file to determine the number of bytes it contains.\n",
            "user: How many bytes is the provided file?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can observe JSON mode in action!"
      ],
      "metadata": {
        "id": "lSJs9oDIgBTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = client.beta.threads.messages.list(thread_id=thread_id_for_response)\n",
        "response = messages.data[0].content[0].text.value\n",
        "completed_flag = json.loads(is_complete(query, response).choices[0].message.content)"
      ],
      "metadata": {
        "id": "MSDsmlDBcYk_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completed_flag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-SKB6TWf_Ra",
        "outputId": "2f9007d4-6fa1-4097-9f22-f925d30bd8a4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'completed': False}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöß BONUS CHALLENGE üöß:\n",
        "\n",
        "Use the components we've constructed so far to build a loop that lets us continue to query the Assistant if the response is not completed!"
      ],
      "metadata": {
        "id": "bivIAVh0dTwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE\n",
        "def query_until_complete(query, assistant_id):\n",
        "    # Initialize the loop condition\n",
        "    completed = False\n",
        "\n",
        "    # Loop until the response is marked as complete\n",
        "    while not completed:\n",
        "        # Query the Assistant\n",
        "        thread_id_for_response = use_assistant(query, assistant_id)\n",
        "\n",
        "        # Fetch messages from the Assistant thread\n",
        "        messages = client.beta.threads.messages.list(thread_id=thread_id_for_response)\n",
        "        response = messages.data[0].content[0].text.value\n",
        "\n",
        "        # Check if the response is complete\n",
        "        completed_flag = json.loads(is_complete(query, response).choices[0].message.content)\n",
        "        completed = completed_flag['completed']\n",
        "\n",
        "        # If not completed, possibly modify the query or handle accordingly before the next iteration\n",
        "        if not completed:\n",
        "            print(\"Response not complete. Querying again...\")\n",
        "\n",
        "            # Here, we could modify the query based on the response or just retry with the same query.\n",
        "            # For simplicity, this example retries with the same query.\n",
        "\n",
        "    # Once complete, print or return the final response\n",
        "    print(\"Final response:\", response)\n",
        "\n",
        "# Example usage\n",
        "query = \"How many bytes is the provided file?\"\n",
        "assistant_id = assistant.id  # Assuming 'assistant' is already defined\n",
        "query_until_complete(query, assistant_id)"
      ],
      "metadata": {
        "id": "vtWh_h_WfjuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Sure You Delete Resources\n",
        "\n",
        "Make sure you delete all the resources you created!\n",
        "\n",
        "This function will help you do so!"
      ],
      "metadata": {
        "id": "VJjYm6gnfWrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_deletion_status = client.beta.assistants.files.delete(\n",
        "  assistant_id=assistant.id,\n",
        "  file_id=file_reference.id\n",
        ")"
      ],
      "metadata": {
        "id": "62b49AleR6m_"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}